"""
Enhanced Dataset Downloader v2
- Multiple fallback sources for UCI dataset
- Additional public datasets from Kaggle/GitHub
- Improved synthetic data generation
- Better data augmentation
"""

import pandas as pd
import requests
from pathlib import Path
import zipfile
import io
import json
from sklearn.model_selection import train_test_split
from datetime import datetime
import time

# Directories
DATA_DIR = Path("data")
RAW_DIR = DATA_DIR / "raw"
PROCESSED_DIR = DATA_DIR / "processed"

RAW_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)


def download_uci_sms_spam():
    """
    Download UCI SMS Spam Collection with multiple fallback sources
    """
    print("\n" + "="*60)
    print("STEP 1: DOWNLOAD UCI SMS SPAM COLLECTION")
    print("="*60)
    
    sources = [
        {
            'name': 'UCI Primary',
            'url': 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip',
            'type': 'zip'
        },
        {
            'name': 'GitHub Mirror 1',
            'url': 'https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/SMSSpamCollection.csv',
            'type': 'csv'
        },
        {
            'name': 'GitHub Mirror 2', 
            'url': 'https://raw.githubusercontent.com/justmarkham/pydata-dc-2016-tutorial/master/data/sms.tsv',
            'type': 'tsv'
        }
    ]
    
    for source in sources:
        try:
            print(f"\nðŸ“¥ Trying {source['name']}...")
            response = requests.get(source['url'], timeout=30)
            response.raise_for_status()
            
            if source['type'] == 'zip':
                with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
                    zip_file.extractall(RAW_DIR)
                df = pd.read_csv(
                    RAW_DIR / "SMSSpamCollection",
                    sep='\t',
                    names=['label', 'message'],
                    encoding='utf-8'
                )
            elif source['type'] == 'csv':
                from io import StringIO
                df = pd.read_csv(StringIO(response.text))
                if 'v1' in df.columns:
                    df = df.rename(columns={'v1': 'label', 'v2': 'message'})
                elif 'label' not in df.columns:
                    df.columns = ['label', 'message']
            elif source['type'] == 'tsv':
                from io import StringIO
                df = pd.read_csv(StringIO(response.text), sep='\t')
                if df.columns[0] != 'label':
                    df.columns = ['label', 'message']
            
            # Standardize labels
            df['label'] = df['label'].str.lower().map({'ham': 'ham', 'spam': 'spam'})
            df = df[df['label'].isin(['ham', 'spam'])]  # Remove any invalid labels
            df['source'] = 'uci'
            df['dataset'] = 'uci_sms_spam'
            df['quality'] = 'high'
            
            print(f"âœ… SUCCESS! Downloaded from {source['name']}")
            print(f"   Total: {len(df)} messages")
            print(f"   - Spam: {len(df[df['label']=='spam'])} ({len(df[df['label']=='spam'])/len(df)*100:.1f}%)")
            print(f"   - Ham: {len(df[df['label']=='ham'])} ({len(df[df['label']=='ham'])/len(df)*100:.1f}%)")
            
            return df
            
        except Exception as e:
            print(f"   âŒ Failed: {e}")
            continue
    
    # All sources failed - create expanded fallback
    print("\nâš ï¸  All sources failed. Creating expanded synthetic dataset...")
    return create_expanded_fallback_dataset()


def create_expanded_fallback_dataset():
    """Create a much larger fallback dataset with realistic patterns"""
    print("   Generating 3,000+ synthetic messages based on common patterns...")
    
    messages = []
    
    # SPAM patterns (1,000 messages)
    spam_templates = [
        "URGENT! Free entry in 2 a weekly competition to win FA Cup final tkts",
        "XXXMobileMovieClub: To use your credit, click the WAP link",
        "Free msg: Txt: CALL to No: 86888 & claim your reward of 3 hours",
        "SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11",
        "WINNER!! As a valued network customer you have been selected",
        "Congratulations ur awarded {prize}! Collect from {url}",
        "PRIVATE! Your 2003 Account Statement for {number} shows {amount}",
        "This is the 2nd time we have tried to contact you. Call {number}",
        "{service} final notice: your subscription expires in {days} days",
        "Text WIN to {number} for your FREE gift worth Â£{amount}",
    ]
    
    for i in range(100):
        for template in spam_templates:
            msg = template.format(
                prize=["$5000", "iPhone 15", "Â£1000", "iPad Pro"][i % 4],
                url=f"www.claim-prize{i}.com",
                number=f"8{i:04d}",
                amount=[100, 500, 1000, 2000][i % 4],
                service=["Netflix", "Spotify", "Amazon Prime", "Disney+"][i % 4],
                days=[3, 7, 14, 30][i % 4]
            )
            messages.append(('spam', msg))
    
    # SMISHING patterns (500 messages)
    smishing_templates = [
        "Your {bank} account has been {action}. Verify at {url} within 24hrs",
        "URGENT: Suspicious login from {location}. Secure account: {url}",
        "Your package delivery failed. Update address: {url}",
        "{service} Security Alert: {threat}. Click: {url}",
        "IRS: Tax refund ${amount} approved. Claim: {url}",
        "Your payment to {person} failed. Retry: {url}",
        "Final notice: Outstanding balance ${amount}. Pay: {url}",
        "Account will be closed unless you verify: {url}",
        "Unusual activity detected. Confirm identity: {url}",
        "{service}: Your account compromised. Reset password: {url}",
    ]
    
    banks = ["Wells Fargo", "Chase", "Bank of America", "Citibank"]
    services = ["PayPal", "Venmo", "Amazon", "Apple", "Microsoft"]
    locations = ["Russia", "China", "Nigeria", "Unknown Location"]
    threats = ["Unauthorized access detected", "New device login", "Password change attempt"]
    
    for i in range(50):
        for template in smishing_templates:
            msg = template.format(
                bank=banks[i % len(banks)],
                action=["suspended", "locked", "compromised"][i % 3],
                url=f"secure-verify{i}.xyz/login",
                location=locations[i % len(locations)],
                service=services[i % len(services)],
                threat=threats[i % len(threats)],
                amount=[150, 350, 500, 1200][i % 4],
                person=["John Smith", "Jane Doe", "Mike Johnson"][i % 3]
            )
            messages.append(('smishing', msg))
    
    # HAM patterns (1,500 messages)
    ham_templates = [
        "Hey, are you free for {activity} {time}?",
        "Don't forget {item} on your way home",
        "Great job on {task}! {praise}",
        "Meeting {when} in {place}",
        "Can you pick up {items} from {place}?",
        "Reminder: {appointment} on {date} at {time}",
        "{name} called earlier. Call back when you can",
        "Thanks for {action}! Really appreciate it",
        "Running {duration} late, be there soon",
        "Left {item} at {place}, can you grab it?",
    ]
    
    activities = ["coffee", "lunch", "dinner", "drinks", "a movie"]
    items = ["milk", "bread", "eggs", "groceries", "my charger"]
    tasks = ["the presentation", "your report", "the meeting", "the project"]
    praises = ["Well done!", "Impressed!", "Great work!", "Nice!"]
    places = ["home", "the office", "the store", "your desk", "the car"]
    
    for i in range(150):
        for template in ham_templates:
            msg = template.format(
                activity=activities[i % len(activities)],
                time=["later", "tomorrow", "this afternoon", "tonight"][i % 4],
                item=items[i % len(items)],
                task=tasks[i % len(tasks)],
                praise=praises[i % len(praises)],
                when=["today", "tomorrow", "next week"][i % 3],
                place=places[i % len(places)],
                items=", ".join([items[i % len(items)], items[(i+1) % len(items)]]),
                appointment=["dentist", "doctor", "haircut", "car service"][i % 4],
                date=["Monday", "Tuesday", "tomorrow", "next week"][i % 4],
                name=["Mom", "Dad", "Sarah", "John", "Mike"][i % 5],
                action=["your help", "dinner", "the gift", "calling"][i % 4],
                duration=["5 mins", "10 mins", "15 mins"][i % 3]
            )
            messages.append(('ham', msg))
    
    df = pd.DataFrame(messages, columns=['label', 'message'])
    df['source'] = 'fallback_expanded'
    df['dataset'] = 'fallback'
    df['quality'] = 'medium'
    df['is_smishing'] = df['label'] == 'smishing'
    df['label'] = df['label'].apply(lambda x: 'spam' if x == 'smishing' else x)
    
    print(f"   âœ… Generated {len(df)} messages")
    return df


def generate_a2p_messages_enhanced():
    """
    Generate comprehensive A2P messages with more variety
    Target: 2,000+ messages
    """
    print("\n" + "="*60)
    print("STEP 2: GENERATE A2P LEGITIMATE MESSAGES (ENHANCED)")
    print("="*60)
    
    messages = []
    
    # 1. TWO-FACTOR AUTHENTICATION (400 messages)
    print("   Generating 2FA/OTP messages...")
    otp_templates = [
        "Your {service} verification code is {code}",
        "{code} is your {service} security code",
        "Use {code} to verify your {service} account. Valid for {mins} minutes",
        "{service}: Your one-time password is {code}",
        "Security code for {service}: {code}. Do not share this code",
        "Your authentication code: {code} (expires in {mins} min)",
        "{code} is your verification code. Use it to sign in to {service}",
        "Verification code: {code}. Someone is trying to sign in to your {service} account",
    ]
    
    services = ["Google", "Microsoft", "Apple", "Facebook", "Instagram", "Twitter", 
                "LinkedIn", "Amazon", "PayPal", "Chase", "Wells Fargo", "Uber", "Lyft",
                "DoorDash", "Netflix", "Spotify", "Discord", "Slack", "GitHub", "Dropbox"]
    
    for i in range(20):
        for template in otp_templates:
            for service in services:
                code = f"{100000 + (i * 13 + services.index(service) * 17) % 900000}"[:6]
                msg = template.format(
                    service=service,
                    code=code,
                    mins=[5, 10, 15, 30][i % 4]
                )
                messages.append({
                    'message': msg,
                    'label': 'ham',
                    'source': 'a2p_synthetic',
                    'dataset': 'a2p_2fa',
                    'quality': 'high',
                    'a2p_type': '2fa'
                })
    
    # 2. TRANSACTIONAL (600 messages)
    print("   Generating transactional messages...")
    trans_templates = [
        "Your {service} order #{order} has shipped. Track: {domain}/track/{order}",
        "Payment of ${amount} to {recipient} successful",
        "{service}: Booking confirmed for {date}. Confirmation #{conf}",
        "Your {service} subscription renewed. ${amount} charged to card ending {last4}",
        "Delivery scheduled for {date} between {time1}-{time2}pm",
        "{service}: Appointment on {date} at {time}. Reply C to confirm",
        "Refund of ${amount} processed. Allow 3-5 business days",
        "Password changed for {service} account {email}",
        "Payment received: ${amount} from {sender}. Available now",
        "{service} reservation confirmed. Check-in: {date}, Room {room}",
    ]
    
    for i in range(60):
        for template in trans_templates:
            msg = template.format(
                service=["Amazon", "Target", "Walmart", "Uber", "Lyft", "DoorDash", 
                         "Grubhub", "Instacart", "Hilton", "Marriott"][i % 10],
                order=f"{10000 + i}",
                domain=["amazon", "target", "walmart", "fedex", "ups"][i % 5],
                amount=f"{10 + (i * 7) % 190}.{i % 100:02d}",
                recipient=["John Smith", "Jane Doe", "Mike Wilson", "Sarah Johnson"][i % 4],
                date=["Dec 31", "Jan 1", "Jan 2", "Jan 3", "tomorrow", "Monday"][i % 6],
                conf=f"ABC{1000 + i}",
                last4=f"{1000 + i}"[-4:],
                time=["2:00", "3:00", "4:00", "5:00"][i % 4],
                time1=["9", "1", "3"][i % 3],
                time2=["12", "4", "6"][i % 3],
                email="user@example.com",
                sender=["Alice Cooper", "Bob Dylan", "Carol King"][i % 3],
                room=f"{100 + i}"
            )
            messages.append({
                'message': msg,
                'label': 'ham',
                'source': 'a2p_synthetic',
                'dataset': 'a2p_transactional',
                'quality': 'high',
                'a2p_type': 'transactional'
            })
    
    # 3. MARKETING (500 messages)
    print("   Generating marketing messages...")
    marketing_templates = [
        "{brand}: {percent}% off {category}! {promo} Shop now. Reply STOP to unsubscribe",
        "Exclusive: {offer} at {brand}. Use code {code}. Valid until {date}",
        "{brand} Rewards: You have {points} points! Redeem now",
        "New {category} collection at {brand}. Shop the latest styles",
        "{brand}: Free shipping on orders over ${amount}. Limited time!",
        "Weekend Sale: Up to {percent}% off at {brand}. Don't miss out!",
        "Member exclusive: Early access to {event}. RSVP at {brand}.com",
        "{brand}: Your favorites are back in stock. Shop before they're gone!",
        "Flash sale! {percent}% off everything at {brand}. Today only",
        "{brand}: Earn double points this weekend. Text STOP to opt out",
    ]
    
    brands = ["Target", "Old Navy", "Gap", "Nike", "Sephora", "Ulta", "Macy's", 
              "Nordstrom", "Best Buy", "Home Depot", "Lowe's", "CVS", "Walgreens"]
    
    for i in range(40):
        for template in marketing_templates:
            msg = template.format(
                brand=brands[i % len(brands)],
                percent=[20, 30, 40, 50][i % 4],
                category=["shoes", "clothing", "electronics", "home goods", "beauty"][i % 5],
                promo=["", "Today only!", "While supplies last!", "24hrs only!"][i % 4],
                offer=["BOGO 50% off", "$10 off $50", "Free gift with purchase"][i % 3],
                code=f"SAVE{10 + i}",
                date=["Sunday", "12/31", "end of month", "1/15"][i % 4],
                points=(i * 50) + 100,
                amount=[35, 50, 75, 100][i % 4],
                event=["Holiday Sale", "VIP Night", "Preview Event"][i % 3]
            )
            messages.append({
                'message': msg,
                'label': 'ham',
                'source': 'a2p_synthetic',
                'dataset': 'a2p_marketing',
                'quality': 'high',
                'a2p_type': 'marketing'
            })
    
    # 4. ALERTS (500 messages)
    print("   Generating alerts and notifications...")
    alert_templates = [
        "Weather Alert: {condition} expected {when}. Stay safe",
        "{school}: School closed {date} due to {reason}",
        "Appointment reminder: {service} {when} at {time}. Reply C to confirm",
        "{service} bill due: ${amount} due by {date}. Pay online to avoid late fee",
        "Prescription ready at {pharmacy}. Pick up after {time}",
        "{service} maintenance: Service offline {when} from {time1}-{time2}",
        "Event reminder: {event} starts in 24 hours. See you there!",
        "Low balance alert: Your checking account is below ${amount}",
        "{service}: Your statement is ready. View at {service}.com",
        "Delivery update: Your package arriving {when} instead of {date}",
    ]
    
    for i in range(50):
        for template in alert_templates:
            msg = template.format(
                condition=["Heavy rain", "Snow", "Severe storms", "High winds"][i % 4],
                when=["tonight", "tomorrow", "this weekend", "today"][i % 4],
                school=["Lincoln Elementary", "Jefferson High", "Washington Middle"][i % 3],
                date=["tomorrow", "today", "Monday", "Tuesday"][i % 4],
                reason=["weather", "power outage", "emergency", "staff development"][i % 4],
                service=["Dentist", "Doctor", "Vet", "Salon"][i % 4],
                time=["2:00pm", "10:00am", "3:30pm", "1:00pm"][i % 4],
                amount=[25, 50, 75, 100, 150][i % 5],
                pharmacy=["CVS", "Walgreens", "Rite Aid"][i % 3],
                time1=["8am", "10pm", "2am"][i % 3],
                time2=["12pm", "2am", "6am"][i % 3],
                event=["Concert", "Meeting", "Appointment"][i % 3]
            )
            messages.append({
                'message': msg,
                'label': 'ham',
                'source': 'a2p_synthetic',
                'dataset': 'a2p_alerts',
                'quality': 'high',
                'a2p_type': 'alerts'
            })
    
    df = pd.DataFrame(messages)
    
    print(f"âœ… A2P Messages: {len(df)} total")
    print(f"   - 2FA/OTP: {len(df[df['a2p_type']=='2fa'])}")
    print(f"   - Transactional: {len(df[df['a2p_type']=='transactional'])}")
    print(f"   - Marketing: {len(df[df['a2p_type']=='marketing'])}")
    print(f"   - Alerts: {len(df[df['a2p_type']=='alerts'])}")
    
    return df


def combine_and_split_datasets(datasets):
    """
    Combine datasets and create stratified splits
    """
    print("\n" + "="*60)
    print("STEP 3: COMBINE & CREATE STRATIFIED SPLITS")
    print("="*60)
    
    # Combine
    combined = pd.concat(datasets, ignore_index=True)
    
    # Remove duplicates
    print(f"\nRemoving duplicates...")
    original_len = len(combined)
    combined = combined.drop_duplicates(subset=['message'], keep='first')
    print(f"  Removed {original_len - len(combined)} duplicates")
    
    # Ensure label consistency
    combined['original_label'] = combined.get('label', 'ham')
    combined['is_smishing'] = combined.get('is_smishing', False)
    combined['label'] = combined['label'].apply(
        lambda x: 'spam' if x in ['spam', 'smishing'] else 'ham'
    )
    
    print(f"\nðŸ“Š Combined Dataset:")
    print(f"   Total: {len(combined)} messages")
    print(f"   - Spam: {len(combined[combined['label']=='spam'])} ({len(combined[combined['label']=='spam'])/len(combined)*100:.1f}%)")
    print(f"   - Ham: {len(combined[combined['label']=='ham'])} ({len(combined[combined['label']=='ham'])/len(combined)*100:.1f}%)")
    
    # Stratified split
    train_df, temp_df = train_test_split(
        combined,
        test_size=0.3,
        stratify=combined['label'],
        random_state=42
    )
    
    val_df, test_df = train_test_split(
        temp_df,
        test_size=0.5,
        stratify=temp_df['label'],
        random_state=42
    )
    
    print(f"\nðŸ“ˆ Stratified Splits:")
    print(f"   Train: {len(train_df):5d} (Spam: {len(train_df[train_df['label']=='spam']):4d}, Ham: {len(train_df[train_df['label']=='ham']):4d})")
    print(f"   Val:   {len(val_df):5d} (Spam: {len(val_df[val_df['label']=='spam']):4d}, Ham: {len(val_df[val_df['label']=='ham']):4d})")
    print(f"   Test:  {len(test_df):5d} (Spam: {len(test_df[test_df['label']=='spam']):4d}, Ham: {len(test_df[test_df['label']=='ham']):4d})")
    
    # Save
    train_df.to_csv(PROCESSED_DIR / "train.csv", index=False)
    val_df.to_csv(PROCESSED_DIR / "val.csv", index=False)
    test_df.to_csv(PROCESSED_DIR / "test.csv", index=False)
    combined.to_csv(PROCESSED_DIR / "combined.csv", index=False)
    
    # Summary
    summary = {
        'created_at': datetime.now().isoformat(),
        'total_messages': len(combined),
        'spam_count': int(len(combined[combined['label']=='spam'])),
        'ham_count': int(len(combined[combined['label']=='ham'])),
        'train_size': len(train_df),
        'val_size': len(val_df),
        'test_size': len(test_df),
    }
    
    with open(PROCESSED_DIR / "dataset_summary.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… Saved to {PROCESSED_DIR}/")
    
    return train_df, val_df, test_df


def download_mendeley_dataset_1():
    """
    Download Mendeley SMS Phishing Dataset 1
    Dataset: f45bkkt8pr - SMS Phishing Dataset for Machine Learning
    """
    print("\n" + "="*60)
    print("STEP 2: DOWNLOAD MENDELEY DATASET 1 (SMS Phishing)")
    print("="*60)
    
    # Note: Mendeley requires authentication for direct download
    # Providing alternative approaches and fallback
    
    try:
        # Try direct download (may require auth)
        url = "https://data.mendeley.com/public-files/datasets/f45bkkt8pr/files/5971db8e-05a6-4c47-b8eb-cbc7f4a9d23f/file_downloaded"
        
        print(f"ðŸ“¥ Attempting download from Mendeley...")
        response = requests.get(url, timeout=30)
        
        if response.status_code == 200:
            # Try to parse as CSV
            from io import StringIO
            df = pd.read_csv(StringIO(response.text))
            
            # Standardize columns
            if 'label' not in df.columns:
                # Try common column names
                if 'Label' in df.columns:
                    df = df.rename(columns={'Label': 'label', 'Text': 'message'})
                elif 'class' in df.columns:
                    df = df.rename(columns={'class': 'label', 'text': 'message'})
            
            # Standardize labels
            df['label'] = df['label'].str.lower()
            df['label'] = df['label'].map({
                'spam': 'spam', 'ham': 'ham', 'legitimate': 'ham',
                'phishing': 'spam', 'smishing': 'spam'
            })
            
            df['source'] = 'mendeley_1'
            df['dataset'] = 'mendeley_phishing_1'
            df['quality'] = 'high'
            
            print(f"âœ… Mendeley Dataset 1: {len(df)} messages")
            print(f"   - Spam: {len(df[df['label']=='spam'])}")
            print(f"   - Ham: {len(df[df['label']=='ham'])}")
            
            return df
            
    except Exception as e:
        print(f"âš ï¸  Direct download failed: {e}")
    
    # Fallback: Create representative samples based on dataset description
    print("   Creating representative samples based on dataset patterns...")
    
    messages = []
    
    # Based on dataset description: modern phishing patterns
    phishing_patterns = [
        "Dear customer, your {service} account requires immediate verification: {url}",
        "Alert: Unusual sign-in activity on your {service} account from {location}. Verify: {url}",
        "Your {service} payment method has expired. Update now: {url}",
        "{service} Security: We detected suspicious activity. Confirm your identity: {url}",
        "Action required: Your {service} account will be suspended unless you verify: {url}",
        "You have a new secure message. Login to view: {url}",
        "Your shipment #{number} requires customs clearance. Pay fee: {url}",
        "Tax refund of ${amount} approved. Claim within 48 hours: {url}",
        "Your card ending in {last4} was charged ${amount}. If not you, verify: {url}",
        "Password reset requested for {email}. Click to confirm: {url}",
    ]
    
    services = ["PayPal", "Bank of America", "Amazon", "Microsoft", "Apple", 
                "Netflix", "USPS", "FedEx", "IRS", "Social Security"]
    
    for i in range(20):
        for pattern in phishing_patterns:
            msg = pattern.format(
                service=services[i % len(services)],
                url=f"secure-{services[i % len(services)].lower().replace(' ', '')}{i}.com/verify",
                location=["Russia", "China", "Unknown"][i % 3],
                number=f"{10000 + i}",
                amount=[50, 100, 250, 500][i % 4],
                last4=f"{1000 + i}"[-4:],
                email="user@example.com"
            )
            messages.append(('spam', msg))
    
    # Add legitimate examples
    legitimate = [
        "Your verification code is {code}. Valid for {mins} minutes.",
        "Payment of ${amount} received from {sender}",
        "Your order #{order} has shipped",
        "Appointment reminder: {service} on {date}",
    ]
    
    for i in range(50):
        for pattern in legitimate:
            msg = pattern.format(
                code=f"{100000 + i}",
                mins=[5, 10, 15][i % 3],
                amount=[25, 50, 100][i % 3],
                sender=["John", "Jane", "Mike"][i % 3],
                order=f"{10000 + i}",
                service=["Dentist", "Doctor"][i % 2],
                date=["tomorrow", "Monday"][i % 2]
            )
            messages.append(('ham', msg))
    
    df = pd.DataFrame(messages, columns=['label', 'message'])
    df['source'] = 'mendeley_1_synthetic'
    df['dataset'] = 'mendeley_phishing_1'
    df['quality'] = 'medium'
    
    print(f"âœ… Created {len(df)} representative messages")
    return df


def download_mendeley_dataset_2():
    """
    Download Mendeley SMS Dataset 2
    Dataset: vmg875v4xs - SMS Spam Collection
    """
    print("\n" + "="*60)
    print("STEP 3: DOWNLOAD MENDELEY DATASET 2 (SMS Spam)")
    print("="*60)
    
    try:
        # Try direct download
        url = "https://data.mendeley.com/public-files/datasets/vmg875v4xs/files/1a6f8c3d-4b8e-4f2c-9c3e-8d7e5f4a3b2c/file_downloaded"
        
        print(f"ðŸ“¥ Attempting download from Mendeley...")
        response = requests.get(url, timeout=30)
        
        if response.status_code == 200:
            from io import StringIO
            df = pd.read_csv(StringIO(response.text))
            
            # Standardize
            if 'label' not in df.columns:
                if 'Category' in df.columns:
                    df = df.rename(columns={'Category': 'label', 'Message': 'message'})
                elif 'type' in df.columns:
                    df = df.rename(columns={'type': 'label', 'sms': 'message'})
            
            df['label'] = df['label'].str.lower().map({
                'spam': 'spam', 'ham': 'ham', 'legitimate': 'ham'
            })
            
            df['source'] = 'mendeley_2'
            df['dataset'] = 'mendeley_spam_2'
            df['quality'] = 'high'
            
            print(f"âœ… Mendeley Dataset 2: {len(df)} messages")
            return df
            
    except Exception as e:
        print(f"âš ï¸  Direct download failed: {e}")
    
    # Fallback: Additional spam patterns
    print("   Creating representative samples...")
    
    messages = []
    
    spam_patterns = [
        "WINNER! You've been selected to receive {prize}. Call {number} to claim",
        "FREE {item}! Reply YES to receive your complimentary gift",
        "Congratulations! You've won {amount} in our weekly draw. Claim: {url}",
        "Limited time offer: {percent}% off {item}. Text {keyword} to {number}",
        "URGENT: Last chance to claim your {prize}. Expires tonight!",
        "You have been chosen for a special {offer}. Reply NOW",
        "Hot singles near you! Visit {url} to connect",
        "Make ${amount}/day working from home. Text INFO to {number}",
        "Your loan application for ${amount} approved! Call {number}",
        "FINAL NOTICE: Claim your {prize} within 24 hours",
    ]
    
    for i in range(30):
        for pattern in spam_patterns:
            msg = pattern.format(
                prize=["iPhone 15", "$5000", "iPad", "Gift Card"][i % 4],
                number=f"555-{1000 + i}",
                item=["vacation", "car", "phone", "laptop"][i % 4],
                amount=[100, 500, 1000, 5000][i % 4],
                url=f"win-prize{i}.com",
                percent=[50, 60, 70, 80][i % 4],
                keyword=["WIN", "FREE", "YES", "CLAIM"][i % 4],
                offer=["promotion", "offer", "deal", "discount"][i % 4]
            )
            messages.append(('spam', msg))
    
    # Ham examples
    ham_patterns = [
        "Hey! Want to grab {meal} {when}?",
        "Running {mins} minutes late",
        "Can you pick up {items} on your way?",
        "Great meeting today. Thanks for {action}!",
        "Don't forget we have {event} tomorrow",
    ]
    
    for i in range(50):
        for pattern in ham_patterns:
            msg = pattern.format(
                meal=["lunch", "dinner", "coffee"][i % 3],
                when=["today", "tomorrow"][i % 2],
                mins=[5, 10, 15][i % 3],
                items=["milk", "bread", "eggs"][i % 3],
                action=["your help", "the update"][i % 2],
                event=["the meeting", "dinner"][i % 2]
            )
            messages.append(('ham', msg))
    
    df = pd.DataFrame(messages, columns=['label', 'message'])
    df['source'] = 'mendeley_2_synthetic'
    df['dataset'] = 'mendeley_spam_2'
    df['quality'] = 'medium'
    
    print(f"âœ… Created {len(df)} representative messages")
    return df


def main():
    """Main execution"""
    print("="*60)
    print("SMS SPAM DETECTION - ENHANCED DATASET PREPARATION V3")
    print("Includes: UCI + 2 Mendeley Datasets + Enhanced A2P")
    print("="*60)
    
    datasets = []
    
    # 1. Try UCI with multiple fallbacks
    uci_df = download_uci_sms_spam()
    if uci_df is not None:
        datasets.append(uci_df)
    
    # 2. Mendeley Dataset 1 (SMS Phishing)
    mendeley1_df = download_mendeley_dataset_1()
    if mendeley1_df is not None:
        datasets.append(mendeley1_df)
    
    # 3. Mendeley Dataset 2 (SMS Spam)
    mendeley2_df = download_mendeley_dataset_2()
    if mendeley2_df is not None:
        datasets.append(mendeley2_df)
    
    # 4. Generate enhanced A2P
    a2p_df = generate_a2p_messages_enhanced()
    datasets.append(a2p_df)
    
    # 3. Combine and split
    if len(datasets) > 0:
        train, val, test = combine_and_split_datasets(datasets)
        
        print("\n" + "="*60)
        print("âœ… DATASET PREPARATION COMPLETE!")
        print("="*60)
        print(f"\nReady for training with {len(pd.read_csv(PROCESSED_DIR / 'combined.csv'))} messages")
        print(f"Next: python src/training/train_all_models.py")
    
    return 0


if __name__ == "__main__":
    exit(main())
